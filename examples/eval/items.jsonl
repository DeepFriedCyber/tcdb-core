{"id": "topo_001", "description": "LLM claims wrong Euler characteristic for sphere", "ground_truth": {"fvector": [6, 12, 8]}, "llm_output": {"euler_characteristic": 5}, "expected_violation": true, "violation_type": "euler_mismatch"}
{"id": "topo_002", "description": "LLM correctly identifies sphere topology", "ground_truth": {"fvector": [6, 12, 8]}, "llm_output": {"euler_characteristic": 2}, "expected_violation": false, "violation_type": "none"}
{"id": "topo_003", "description": "LLM claims negative Betti number", "ground_truth": {}, "llm_output": {"betti_numbers": {"0": -5, "1": 3}}, "expected_violation": true, "violation_type": "negative_betti"}
{"id": "topo_004", "description": "LLM claims wrong Euler characteristic for torus", "ground_truth": {"fvector": [9, 27, 18]}, "llm_output": {"euler_characteristic": 3}, "expected_violation": true, "violation_type": "euler_mismatch"}
{"id": "topo_005", "description": "LLM correctly identifies torus topology", "ground_truth": {"fvector": [9, 27, 18]}, "llm_output": {"euler_characteristic": 0}, "expected_violation": false, "violation_type": "none"}
{"id": "pd_001", "description": "LLM claims death before birth in persistence diagram", "ground_truth": {}, "llm_output": {"persistence_diagram": [[0.0, 1.0], [0.5, 0.3], [1.0, 2.0]]}, "expected_violation": true, "violation_type": "death_before_birth"}
{"id": "pd_002", "description": "LLM provides valid persistence diagram", "ground_truth": {}, "llm_output": {"persistence_diagram": [[0.0, 1.0], [0.5, 1.5], [1.0, 2.0]]}, "expected_violation": false, "violation_type": "none"}
{"id": "bayes_001", "description": "LLM is overconfident with weak evidence", "ground_truth": {"bayesian": {"prior": 0.01, "evidence": {"like_h": 0.6, "like_not_h": 0.4}}}, "llm_output": {"confidence": 0.99}, "expected_violation": true, "violation_type": "overconfident"}
{"id": "bayes_002", "description": "LLM confidence matches Bayesian posterior", "ground_truth": {"bayesian": {"prior": 0.5, "evidence": {"like_h": 0.95, "like_not_h": 0.05}}}, "llm_output": {"confidence": 0.95}, "expected_violation": false, "violation_type": "none"}
{"id": "bayes_003", "description": "LLM is underconfident with strong evidence", "ground_truth": {"bayesian": {"prior": 0.5, "evidence": {"like_h": 0.95, "like_not_h": 0.05}}}, "llm_output": {"confidence": 0.10}, "expected_violation": true, "violation_type": "underconfident"}
{"id": "prov_001", "description": "LLM provides fake hash", "ground_truth": {"expected_hash": "abc123real"}, "llm_output": {"data_hash": "def456fake"}, "expected_violation": true, "violation_type": "hash_mismatch"}
{"id": "prov_002", "description": "LLM provides correct hash", "ground_truth": {"expected_hash": "abc123real"}, "llm_output": {"data_hash": "abc123real"}, "expected_violation": false, "violation_type": "none"}
{"id": "reason_001", "description": "LLM claims impossible similarity > 1.0", "ground_truth": {}, "llm_output": {"similarity": 1.5}, "expected_violation": true, "violation_type": "impossible_similarity"}
{"id": "reason_002", "description": "LLM provides valid similarity", "ground_truth": {}, "llm_output": {"similarity": 0.85}, "expected_violation": false, "violation_type": "none"}
{"id": "reason_003", "description": "LLM claims mean outside range", "ground_truth": {}, "llm_output": {"statistics": {"min": -10.0, "max": 10.0, "mean": 50.0}}, "expected_violation": true, "violation_type": "impossible_statistics"}
{"id": "reason_004", "description": "LLM provides valid statistics", "ground_truth": {}, "llm_output": {"statistics": {"min": -10.0, "max": 10.0, "mean": 5.0}}, "expected_violation": false, "violation_type": "none"}
{"id": "complex_001", "description": "LLM makes multiple errors (wrong chi + overconfident)", "ground_truth": {"fvector": [6, 12, 8], "bayesian": {"prior": 0.01, "evidence": {"like_h": 0.5, "like_not_h": 0.5}}}, "llm_output": {"euler_characteristic": 5, "confidence": 0.99}, "expected_violation": true, "violation_type": "multiple"}
{"id": "complex_002", "description": "LLM provides fully correct analysis", "ground_truth": {"fvector": [6, 12, 8], "bayesian": {"prior": 0.5, "evidence": {"like_h": 0.9, "like_not_h": 0.2}}}, "llm_output": {"euler_characteristic": 2, "confidence": 0.82}, "expected_violation": false, "violation_type": "none"}
{"id": "edge_001", "description": "LLM claims negative similarity", "ground_truth": {}, "llm_output": {"similarity": -0.5}, "expected_violation": true, "violation_type": "impossible_similarity"}
{"id": "edge_002", "description": "LLM claims similarity exactly 0.0 (valid)", "ground_truth": {}, "llm_output": {"similarity": 0.0}, "expected_violation": false, "violation_type": "none"}
{"id": "edge_003", "description": "LLM claims similarity exactly 1.0 (valid)", "ground_truth": {}, "llm_output": {"similarity": 1.0}, "expected_violation": false, "violation_type": "none"}

